#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
íŠ¹í—ˆ LLM í›ˆë ¨ ë° íŒŒì¸íŠœë‹ ì‹œìŠ¤í…œ
Patent LLM Training and Fine-tuning System

íŠ¹í—ˆ ë°ì´í„°ë¥¼ í™œìš©í•œ LLM íŒŒì¸íŠœë‹ ë° í›ˆë ¨ ê´€ë¦¬ ì‹œìŠ¤í…œ

MIT License
Copyright (c) 2025
"""

import os
import json
import sqlite3
import logging
from typing import List, Dict, Optional, Tuple, Any
from dataclasses import dataclass, asdict
import numpy as np
import pandas as pd
from datetime import datetime
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import transformers
from transformers import (
    AutoTokenizer, AutoModelForCausalLM, 
    TrainingArguments, Trainer,
    DataCollatorForLanguageModeling
)
from peft import LoraConfig, get_peft_model, TaskType
import wandb
from pathlib import Path

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class TrainingConfig:
    """í›ˆë ¨ ì„¤ì • í´ë˜ìŠ¤"""
    base_model_name: str = "microsoft/DialoGPT-medium"
    max_length: int = 512
    batch_size: int = 4
    learning_rate: float = 5e-5
    num_epochs: int = 3
    warmup_steps: int = 100
    save_steps: int = 500
    eval_steps: int = 500
    logging_steps: int = 100
    output_dir: str = "patent_llm_output"
    use_lora: bool = True
    lora_r: int = 16
    lora_alpha: int = 32
    lora_dropout: float = 0.1
    gradient_accumulation_steps: int = 4
    fp16: bool = True
    dataloader_num_workers: int = 4

@dataclass
class TrainingExample:
    """í›ˆë ¨ ì˜ˆì œ ë°ì´í„° í´ë˜ìŠ¤"""
    input_text: str
    target_text: str
    patent_id: str
    example_type: str  # "claim_analysis", "implementation_generation", "evaluation"
    metadata: Dict[str, Any]

class PatentTrainingDataset(Dataset):
    """íŠ¹í—ˆ í›ˆë ¨ ë°ì´í„°ì…‹"""
    
    def __init__(self, examples: List[TrainingExample], tokenizer, max_length: int = 512):
        self.examples = examples
        self.tokenizer = tokenizer
        self.max_length = max_length
    
    def __len__(self):
        return len(self.examples)
    
    def __getitem__(self, idx):
        example = self.examples[idx]
        
        # ì…ë ¥ê³¼ íƒ€ê²Ÿì„ ê²°í•©í•˜ì—¬ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ ë§Œë“¦
        full_text = f"{example.input_text} {self.tokenizer.eos_token} {example.target_text}"
        
        # í† í¬ë‚˜ì´ì§•
        encoding = self.tokenizer(
            full_text,
            truncation=True,
            padding="max_length",
            max_length=self.max_length,
            return_tensors="pt"
        )
        
        input_ids = encoding["input_ids"].squeeze()
        attention_mask = encoding["attention_mask"].squeeze()
        
        # ë¼ë²¨ì€ ì…ë ¥ê³¼ ë™ì¼ (ì–¸ì–´ ëª¨ë¸ë§)
        labels = input_ids.clone()
        
        return {
            "input_ids": input_ids,
            "attention_mask": attention_mask,
            "labels": labels
        }

class PatentDatasetBuilder:
    """íŠ¹í—ˆ í›ˆë ¨ ë°ì´í„°ì…‹ êµ¬ì¶•ê¸°"""
    
    def __init__(self, processed_patents_db: str = "processed_patents.db"):
        self.db_path = processed_patents_db
        self.prompt_templates = {
            "claim_analysis": {
                "input": "ë‹¤ìŒ íŠ¹í—ˆ í´ë ˆì„ì„ ë¶„ì„í•˜ì—¬ í•µì‹¬ ê¸°ìˆ  ê°œë…ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”:\n\níŠ¹í—ˆ ì œëª©: {title}\ní´ë ˆì„: {claim}\n\në¶„ì„:",
                "target": "í•µì‹¬ ì•Œê³ ë¦¬ì¦˜: {core_algorithm}\nê¸°ìˆ  êµ¬ì„±ìš”ì†Œ: {components}\nêµ¬í˜„ ìš”êµ¬ì‚¬í•­: {requirements}"
            },
            "implementation_generation": {
                "input": "ë‹¤ìŒ ê¸°ìˆ  ê°œë…ì„ ë°”íƒ•ìœ¼ë¡œ Python êµ¬í˜„ ì½”ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:\n\nê¸°ìˆ  ê°œë…: {concept}\nêµ¬ì„±ìš”ì†Œ: {components}\n\nêµ¬í˜„:",
                "target": "{implementation_code}"
            },
            "evaluation": {
                "input": "ë‹¤ìŒ êµ¬í˜„ ì½”ë“œë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”:\n\nì½”ë“œ:\n{code}\n\ní‰ê°€:",
                "target": "êµ¬ë¬¸ ì •í™•ì„±: {syntax_score}\nì™„ì„±ë„: {completeness_score}\nê¸°ëŠ¥ì„±: {functionality_score}\nì „ì²´ í‰ê°€: {overall_assessment}"
            }
        }
    
    def build_training_dataset(self, max_examples: int = 10000) -> List[TrainingExample]:
        """í›ˆë ¨ ë°ì´í„°ì…‹ êµ¬ì¶•"""
        
        logger.info("íŠ¹í—ˆ í›ˆë ¨ ë°ì´í„°ì…‹ êµ¬ì¶• ì‹œì‘")
        
        examples = []
        
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì²˜ë¦¬ëœ íŠ¹í—ˆ ë°ì´í„° ë¡œë“œ
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT patent_id, processed_text, structured_claims, technical_keywords
            FROM processed_patents
            LIMIT ?
        ''', (max_examples,))
        
        rows = cursor.fetchall()
        conn.close()
        
        for row in rows:
            patent_id, processed_text, structured_claims_json, keywords_json = row
            
            try:
                structured_claims = json.loads(structured_claims_json) if structured_claims_json else []
                keywords = json.loads(keywords_json) if keywords_json else []
                
                # í´ë ˆì„ ë¶„ì„ ì˜ˆì œ ìƒì„±
                examples.extend(self._create_claim_analysis_examples(patent_id, structured_claims, keywords))
                
                # êµ¬í˜„ ìƒì„± ì˜ˆì œ ìƒì„±
                examples.extend(self._create_implementation_examples(patent_id, structured_claims, keywords))
                
                # í‰ê°€ ì˜ˆì œ ìƒì„±
                examples.extend(self._create_evaluation_examples(patent_id, structured_claims))
                
            except Exception as e:
                logger.error(f"ë°ì´í„°ì…‹ êµ¬ì¶• ì˜¤ë¥˜ (íŠ¹í—ˆ {patent_id}): {e}")
        
        logger.info(f"í›ˆë ¨ ë°ì´í„°ì…‹ êµ¬ì¶• ì™„ë£Œ: {len(examples)}ê°œ ì˜ˆì œ")
        return examples
    
    def _create_claim_analysis_examples(self, patent_id: str, claims: List[Dict], keywords: List[str]) -> List[TrainingExample]:
        """í´ë ˆì„ ë¶„ì„ ì˜ˆì œ ìƒì„±"""
        examples = []
        
        for claim in claims[:3]:  # ìƒìœ„ 3ê°œ í´ë ˆì„ë§Œ ì‚¬ìš©
            input_text = self.prompt_templates["claim_analysis"]["input"].format(
                title=f"Patent {patent_id}",
                claim=claim.get("content", "")[:500]  # ê¸¸ì´ ì œí•œ
            )
            
            target_text = self.prompt_templates["claim_analysis"]["target"].format(
                core_algorithm=f"ë¶„ì„ëœ ì•Œê³ ë¦¬ì¦˜ (í´ë ˆì„ {claim.get('claim_number', 1)})",
                components=", ".join(claim.get("technical_elements", [])[:3]),
                requirements=f"êµ¬í˜„ ìš”êµ¬ì‚¬í•­ ({claim.get('type', 'unknown')} íƒ€ì…)"
            )
            
            example = TrainingExample(
                input_text=input_text,
                target_text=target_text,
                patent_id=patent_id,
                example_type="claim_analysis",
                metadata={"claim_number": claim.get("claim_number", 1)}
            )
            examples.append(example)
        
        return examples
    
    def _create_implementation_examples(self, patent_id: str, claims: List[Dict], keywords: List[str]) -> List[TrainingExample]:
        """êµ¬í˜„ ìƒì„± ì˜ˆì œ ìƒì„±"""
        examples = []
        
        if claims:
            main_claim = claims[0]  # ì²« ë²ˆì§¸ í´ë ˆì„ ì‚¬ìš©
            
            input_text = self.prompt_templates["implementation_generation"]["input"].format(
                concept=main_claim.get("content", "")[:300],
                components=", ".join(main_claim.get("technical_elements", [])[:3])
            )
            
            # ê°„ë‹¨í•œ êµ¬í˜„ ì½”ë“œ í…œí”Œë¦¿ ìƒì„±
            implementation_code = self._generate_sample_implementation(main_claim, keywords)
            
            target_text = self.prompt_templates["implementation_generation"]["target"].format(
                implementation_code=implementation_code
            )
            
            example = TrainingExample(
                input_text=input_text,
                target_text=target_text,
                patent_id=patent_id,
                example_type="implementation_generation",
                metadata={"claim_type": main_claim.get("type", "unknown")}
            )
            examples.append(example)
        
        return examples
    
    def _create_evaluation_examples(self, patent_id: str, claims: List[Dict]) -> List[TrainingExample]:
        """í‰ê°€ ì˜ˆì œ ìƒì„±"""
        examples = []
        
        # ìƒ˜í”Œ ì½”ë“œì™€ í‰ê°€ ìƒì„±
        sample_code = """
def patent_algorithm():
    # íŠ¹í—ˆ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
    result = process_input()
    return result

def process_input():
    return "processed"
"""
        
        input_text = self.prompt_templates["evaluation"]["input"].format(code=sample_code)
        
        target_text = self.prompt_templates["evaluation"]["target"].format(
            syntax_score="9/10",
            completeness_score="7/10",
            functionality_score="6/10",
            overall_assessment="ê¸°ë³¸ì ì¸ êµ¬ì¡°ëŠ” ê°–ì¶”ì—ˆìœ¼ë‚˜ êµ¬ì²´ì ì¸ êµ¬í˜„ì´ í•„ìš”í•¨"
        )
        
        example = TrainingExample(
            input_text=input_text,
            target_text=target_text,
            patent_id=patent_id,
            example_type="evaluation",
            metadata={}
        )
        examples.append(example)
        
        return examples
    
    def _generate_sample_implementation(self, claim: Dict, keywords: List[str]) -> str:
        """ìƒ˜í”Œ êµ¬í˜„ ì½”ë“œ ìƒì„±"""
        claim_type = claim.get("type", "method")
        
        if claim_type == "method":
            return f"""
import numpy as np

def patent_method():
    \"\"\"
    íŠ¹í—ˆ ë°©ë²• êµ¬í˜„
    í´ë ˆì„: {claim.get('content', '')[:100]}...
    \"\"\"
    # ì…ë ¥ ì²˜ë¦¬
    input_data = preprocess_input()
    
    # í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰
    result = core_algorithm(input_data)
    
    # ê²°ê³¼ í›„ì²˜ë¦¬
    output = postprocess_result(result)
    
    return output

def preprocess_input():
    return np.array([1, 2, 3])

def core_algorithm(data):
    return data * 2

def postprocess_result(result):
    return result.tolist()
"""
        else:
            return f"""
class PatentApparatus:
    \"\"\"
    íŠ¹í—ˆ ì¥ì¹˜ êµ¬í˜„
    í´ë ˆì„: {claim.get('content', '')[:100]}...
    \"\"\"
    
    def __init__(self):
        self.components = []
        self.state = "initialized"
    
    def operate(self):
        self.state = "operating"
        return self.process()
    
    def process(self):
        return "processed_output"
"""

class PatentLLMTrainer:
    """íŠ¹í—ˆ LLM í›ˆë ¨ê¸°"""
    
    def __init__(self, config: TrainingConfig):
        self.config = config
        self.tokenizer = None
        self.model = None
        self.training_dataset = None
        self.eval_dataset = None
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        Path(config.output_dir).mkdir(parents=True, exist_ok=True)
    
    def setup_model_and_tokenizer(self):
        """ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì„¤ì •"""
        logger.info(f"ëª¨ë¸ ë¡œë”©: {self.config.base_model_name}")
        
        # í† í¬ë‚˜ì´ì € ë¡œë“œ
        self.tokenizer = AutoTokenizer.from_pretrained(self.config.base_model_name)
        
        # íŒ¨ë”© í† í° ì„¤ì •
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = AutoModelForCausalLM.from_pretrained(
            self.config.base_model_name,
            torch_dtype=torch.float16 if self.config.fp16 else torch.float32,
            device_map="auto" if torch.cuda.is_available() else None
        )
        
        # LoRA ì„¤ì • ì ìš©
        if self.config.use_lora:
            logger.info("LoRA ì„¤ì • ì ìš©")
            lora_config = LoraConfig(
                task_type=TaskType.CAUSAL_LM,
                r=self.config.lora_r,
                lora_alpha=self.config.lora_alpha,
                lora_dropout=self.config.lora_dropout,
                target_modules=["q_proj", "v_proj", "k_proj", "o_proj"]
            )
            self.model = get_peft_model(self.model, lora_config)
            self.model.print_trainable_parameters()
    
    def prepare_datasets(self, training_examples: List[TrainingExample], 
                        eval_split: float = 0.1):
        """ë°ì´í„°ì…‹ ì¤€ë¹„"""
        logger.info("í›ˆë ¨ ë°ì´í„°ì…‹ ì¤€ë¹„")
        
        # í›ˆë ¨/í‰ê°€ ë¶„í• 
        split_idx = int(len(training_examples) * (1 - eval_split))
        train_examples = training_examples[:split_idx]
        eval_examples = training_examples[split_idx:]
        
        # ë°ì´í„°ì…‹ ìƒì„±
        self.training_dataset = PatentTrainingDataset(
            train_examples, self.tokenizer, self.config.max_length
        )
        self.eval_dataset = PatentTrainingDataset(
            eval_examples, self.tokenizer, self.config.max_length
        )
        
        logger.info(f"í›ˆë ¨ ì˜ˆì œ: {len(train_examples)}, í‰ê°€ ì˜ˆì œ: {len(eval_examples)}")
    
    def train(self):
        """ëª¨ë¸ í›ˆë ¨"""
        if not self.model or not self.training_dataset:
            raise ValueError("ëª¨ë¸ê³¼ ë°ì´í„°ì…‹ì„ ë¨¼ì € ì„¤ì •í•´ì£¼ì„¸ìš”.")
        
        logger.info("íŠ¹í—ˆ LLM í›ˆë ¨ ì‹œì‘")
        
        # í›ˆë ¨ ì¸ì ì„¤ì •
        training_args = TrainingArguments(
            output_dir=self.config.output_dir,
            num_train_epochs=self.config.num_epochs,
            per_device_train_batch_size=self.config.batch_size,
            per_device_eval_batch_size=self.config.batch_size,
            gradient_accumulation_steps=self.config.gradient_accumulation_steps,
            learning_rate=self.config.learning_rate,
            warmup_steps=self.config.warmup_steps,
            logging_steps=self.config.logging_steps,
            save_steps=self.config.save_steps,
            eval_steps=self.config.eval_steps,
            evaluation_strategy="steps",
            save_strategy="steps",
            load_best_model_at_end=True,
            metric_for_best_model="eval_loss",
            greater_is_better=False,
            fp16=self.config.fp16,
            dataloader_num_workers=self.config.dataloader_num_workers,
            remove_unused_columns=False,
            report_to=["wandb"] if wandb.run else None
        )
        
        # ë°ì´í„° ì½œë ˆì´í„°
        data_collator = DataCollatorForLanguageModeling(
            tokenizer=self.tokenizer,
            mlm=False  # ì¸ê³¼ì  ì–¸ì–´ ëª¨ë¸ë§
        )
        
        # íŠ¸ë ˆì´ë„ˆ ìƒì„±
        trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=self.training_dataset,
            eval_dataset=self.eval_dataset,
            data_collator=data_collator,
            tokenizer=self.tokenizer
        )
        
        # í›ˆë ¨ ì‹¤í–‰
        trainer.train()
        
        # ìµœì¢… ëª¨ë¸ ì €ì¥
        trainer.save_model()
        self.tokenizer.save_pretrained(self.config.output_dir)
        
        logger.info(f"í›ˆë ¨ ì™„ë£Œ. ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {self.config.output_dir}")
    
    def evaluate_model(self, test_examples: List[TrainingExample]) -> Dict[str, float]:
        """ëª¨ë¸ í‰ê°€"""
        if not self.model:
            raise ValueError("ëª¨ë¸ì„ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”.")
        
        logger.info("ëª¨ë¸ í‰ê°€ ì‹œì‘")
        
        test_dataset = PatentTrainingDataset(test_examples, self.tokenizer, self.config.max_length)
        
        # í‰ê°€ ë©”íŠ¸ë¦­ ê³„ì‚°
        total_loss = 0.0
        correct_predictions = 0
        total_predictions = 0
        
        self.model.eval()
        with torch.no_grad():
            for i, batch in enumerate(DataLoader(test_dataset, batch_size=self.config.batch_size)):
                if torch.cuda.is_available():
                    batch = {k: v.cuda() for k, v in batch.items()}
                
                outputs = self.model(**batch)
                loss = outputs.loss
                total_loss += loss.item()
                
                # ê°„ë‹¨í•œ ì •í™•ë„ ê³„ì‚° (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë©”íŠ¸ë¦­ í•„ìš”)
                predictions = torch.argmax(outputs.logits, dim=-1)
                correct_predictions += (predictions == batch["labels"]).sum().item()
                total_predictions += batch["labels"].numel()
        
        avg_loss = total_loss / len(test_dataset)
        accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0.0
        
        metrics = {
            "eval_loss": avg_loss,
            "eval_accuracy": accuracy,
            "eval_perplexity": np.exp(avg_loss)
        }
        
        logger.info(f"í‰ê°€ ê²°ê³¼: {metrics}")
        return metrics

class PatentLLMManager:
    """íŠ¹í—ˆ LLM ê´€ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, models_dir: str = "patent_models"):
        self.models_dir = Path(models_dir)
        self.models_dir.mkdir(parents=True, exist_ok=True)
        
        self.db_path = "patent_llm_training.db"
        self.init_database()
    
    def init_database(self):
        """í›ˆë ¨ ê¸°ë¡ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS training_runs (
                run_id TEXT PRIMARY KEY,
                model_name TEXT,
                config TEXT,
                start_time TEXT,
                end_time TEXT,
                final_metrics TEXT,
                model_path TEXT,
                status TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def start_training_run(self, config: TrainingConfig, dataset_size: int) -> str:
        """í›ˆë ¨ ì‹¤í–‰ ì‹œì‘"""
        run_id = f"patent_llm_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        logger.info(f"í›ˆë ¨ ì‹¤í–‰ ì‹œì‘: {run_id}")
        
        try:
            # ë°ì´í„°ì…‹ êµ¬ì¶•
            dataset_builder = PatentDatasetBuilder()
            training_examples = dataset_builder.build_training_dataset(dataset_size)
            
            if not training_examples:
                raise ValueError("í›ˆë ¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # í›ˆë ¨ê¸° ì´ˆê¸°í™”
            trainer = PatentLLMTrainer(config)
            trainer.setup_model_and_tokenizer()
            trainer.prepare_datasets(training_examples)
            
            # í›ˆë ¨ ê¸°ë¡ ì €ì¥
            self._save_training_run(run_id, config, "running")
            
            # í›ˆë ¨ ì‹¤í–‰
            trainer.train()
            
            # í‰ê°€ ì‹¤í–‰
            eval_examples = training_examples[-100:]  # ë§ˆì§€ë§‰ 100ê°œë¡œ í‰ê°€
            metrics = trainer.evaluate_model(eval_examples)
            
            # ëª¨ë¸ ì €ì¥ ê²½ë¡œ
            model_path = self.models_dir / run_id
            
            # í›ˆë ¨ ì™„ë£Œ ê¸°ë¡
            self._update_training_run(run_id, metrics, str(model_path), "completed")
            
            logger.info(f"í›ˆë ¨ ì™„ë£Œ: {run_id}")
            return run_id
            
        except Exception as e:
            logger.error(f"í›ˆë ¨ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            self._update_training_run(run_id, {}, "", "failed")
            raise
    
    def _save_training_run(self, run_id: str, config: TrainingConfig, status: str):
        """í›ˆë ¨ ì‹¤í–‰ ê¸°ë¡ ì €ì¥"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO training_runs 
            (run_id, model_name, config, start_time, status)
            VALUES (?, ?, ?, ?, ?)
        ''', (
            run_id,
            config.base_model_name,
            json.dumps(asdict(config)),
            datetime.now().isoformat(),
            status
        ))
        
        conn.commit()
        conn.close()
    
    def _update_training_run(self, run_id: str, metrics: Dict, model_path: str, status: str):
        """í›ˆë ¨ ì‹¤í–‰ ê¸°ë¡ ì—…ë°ì´íŠ¸"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            UPDATE training_runs 
            SET end_time = ?, final_metrics = ?, model_path = ?, status = ?
            WHERE run_id = ?
        ''', (
            datetime.now().isoformat(),
            json.dumps(metrics),
            model_path,
            status,
            run_id
        ))
        
        conn.commit()
        conn.close()
    
    def get_training_history(self) -> List[Dict]:
        """í›ˆë ¨ ê¸°ë¡ ì¡°íšŒ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT run_id, model_name, start_time, end_time, final_metrics, status
            FROM training_runs
            ORDER BY created_at DESC
        ''')
        
        rows = cursor.fetchall()
        conn.close()
        
        history = []
        for row in rows:
            run_id, model_name, start_time, end_time, metrics_json, status = row
            
            metrics = json.loads(metrics_json) if metrics_json else {}
            
            history.append({
                "run_id": run_id,
                "model_name": model_name,
                "start_time": start_time,
                "end_time": end_time,
                "metrics": metrics,
                "status": status
            })
        
        return history

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 80)
    print("ğŸš€ íŠ¹í—ˆ LLM í›ˆë ¨ ë° íŒŒì¸íŠœë‹ ì‹œìŠ¤í…œ")
    print("Patent LLM Training and Fine-tuning System")
    print("=" * 80)
    
    # ê´€ë¦¬ì ì´ˆê¸°í™”
    manager = PatentLLMManager()
    
    while True:
        print("\nğŸ“‹ ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
        print("1. ğŸ¯ ìƒˆ í›ˆë ¨ ì‹¤í–‰")
        print("2. ğŸ“Š í›ˆë ¨ ê¸°ë¡ ì¡°íšŒ")
        print("3. âš™ï¸ í›ˆë ¨ ì„¤ì • êµ¬ì„±")
        print("4. ğŸ“ˆ ë°ì´í„°ì…‹ í†µê³„")
        print("5. âŒ ì¢…ë£Œ")
        
        choice = input("\nì„ íƒ (1-5): ").strip()
        
        if choice == '1':
            print("\nğŸ¯ ìƒˆ í›ˆë ¨ ì‹¤í–‰ ì„¤ì •")
            
            # ê¸°ë³¸ ì„¤ì •
            config = TrainingConfig()
            
            # ì‚¬ìš©ì ì…ë ¥
            model_name = input(f"ë² ì´ìŠ¤ ëª¨ë¸ [{config.base_model_name}]: ").strip()
            if model_name:
                config.base_model_name = model_name
            
            epochs_input = input(f"í›ˆë ¨ ì—í¬í¬ ìˆ˜ [{config.num_epochs}]: ").strip()
            if epochs_input.isdigit():
                config.num_epochs = int(epochs_input)
            
            dataset_size_input = input("ë°ì´í„°ì…‹ í¬ê¸° [1000]: ").strip()
            dataset_size = int(dataset_size_input) if dataset_size_input.isdigit() else 1000
            
            use_lora = input(f"LoRA ì‚¬ìš© ì—¬ë¶€ (y/n) [{'y' if config.use_lora else 'n'}]: ").strip().lower()
            if use_lora in ['y', 'n']:
                config.use_lora = use_lora == 'y'
            
            print(f"\ní›ˆë ¨ ì‹œì‘...")
            try:
                run_id = manager.start_training_run(config, dataset_size)
                print(f"âœ… í›ˆë ¨ ì™„ë£Œ: {run_id}")
            except Exception as e:
                print(f"âŒ í›ˆë ¨ ì‹¤íŒ¨: {e}")
        
        elif choice == '2':
            history = manager.get_training_history()
            
            if history:
                print(f"\nğŸ“Š í›ˆë ¨ ê¸°ë¡ ({len(history)}ê°œ):")
                for i, run in enumerate(history[:10], 1):  # ìµœê·¼ 10ê°œë§Œ í‘œì‹œ
                    print(f"{i}. {run['run_id']}")
                    print(f"   ëª¨ë¸: {run['model_name']}")
                    print(f"   ìƒíƒœ: {run['status']}")
                    print(f"   ì‹œì‘: {run['start_time']}")
                    if run['metrics']:
                        print(f"   í‰ê°€ ì†ì‹¤: {run['metrics'].get('eval_loss', 'N/A'):.4f}")
                    print()
            else:
                print("í›ˆë ¨ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        elif choice == '3':
            print("\nâš™ï¸ í›ˆë ¨ ì„¤ì • êµ¬ì„±")
            config = TrainingConfig()
            print(f"í˜„ì¬ ì„¤ì •:")
            print(f"- ë² ì´ìŠ¤ ëª¨ë¸: {config.base_model_name}")
            print(f"- ìµœëŒ€ ê¸¸ì´: {config.max_length}")
            print(f"- ë°°ì¹˜ í¬ê¸°: {config.batch_size}")
            print(f"- í•™ìŠµë¥ : {config.learning_rate}")
            print(f"- ì—í¬í¬ ìˆ˜: {config.num_epochs}")
            print(f"- LoRA ì‚¬ìš©: {config.use_lora}")
        
        elif choice == '4':
            print("\nğŸ“ˆ ë°ì´í„°ì…‹ í†µê³„")
            try:
                builder = PatentDatasetBuilder()
                examples = builder.build_training_dataset(100)  # ìƒ˜í”Œ 100ê°œ
                
                type_counts = {}
                for example in examples:
                    type_counts[example.example_type] = type_counts.get(example.example_type, 0) + 1
                
                print(f"ì´ ì˜ˆì œ ìˆ˜: {len(examples)}")
                print("ì˜ˆì œ íƒ€ì…ë³„ ë¶„í¬:")
                for example_type, count in type_counts.items():
                    print(f"  - {example_type}: {count}ê°œ")
                
            except Exception as e:
                print(f"âŒ ë°ì´í„°ì…‹ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        elif choice == '5':
            print("ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        
        else:
            print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")

if __name__ == "__main__":
    main()

